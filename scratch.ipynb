{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dcc6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------- HYPERPARAMS ---------------------\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Scene/event sizes\n",
    "T = 2              # time steps (x0, x1)\n",
    "N = 8              # number of entities\n",
    "DX = 2             # features per entity: 2D position only\n",
    "\n",
    "# Model\n",
    "DW = 16            # dimension of concept code w\n",
    "HIDDEN = 128\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "DEMO_SHOTS = 5     # few-shot demos per concept instance\n",
    "STEPS = 800        # training iterations (increase to 5000-10000 for better quality)\n",
    "LR = 1e-3\n",
    "K_SGLD = 10\n",
    "ALPHA_X = 1e-2     # SGLD step for x\n",
    "ALPHA_A = 5e-3     # SGLD step for a\n",
    "LAMBDA_KL = 1.0\n",
    "\n",
    "# Eval/visualization\n",
    "EVAL_BATCH = 1     # visualize a single instance\n",
    "ATTN_THRESHOLD = 0.5\n",
    "\n",
    "# --------------------- SEEDING ---------------------\n",
    "def seed_all(seed:int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_all(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242b015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, act=nn.ReLU, out_act=None):\n",
    "    layers = []\n",
    "    for i in range(len(sizes)-1):\n",
    "        layers += [nn.Linear(sizes[i], sizes[i+1])]\n",
    "        if i < len(sizes)-2:\n",
    "            layers += [act()]\n",
    "        elif out_act is not None:\n",
    "            layers += [out_act()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ff03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mlp([20, 128, 128, 128], act=nn.ReLU, out_act=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38889d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=128, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529ce961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor:\n",
      "tensor([[-1.5304,  0.4735,  0.4727],\n",
      "        [-0.0988,  0.3830, -0.9131],\n",
      "        [ 1.5844,  0.9066, -0.0847]])\n",
      "\n",
      "Output tensor after sigmoid:\n",
      "tensor([[0.1779, 0.6162, 0.6160],\n",
      "        [0.4753, 0.5946, 0.2864],\n",
      "        [0.8298, 0.7123, 0.4788]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create an input tensor\n",
    "x = torch.randn(3, 3)\n",
    "\n",
    "# Apply the sigmoid function\n",
    "y = torch.sigmoid(x)\n",
    "\n",
    "print(\"Input tensor:\")\n",
    "print(x)\n",
    "print(\"\\nOutput tensor after sigmoid:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5b6e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([1, 2, 3, 4]), shape: torch.Size([4])\n",
      "Unsqueeze at dim 0: tensor([[1, 2, 3, 4]]), shape: torch.Size([1, 4])\n",
      "Unsqueeze at dim 1: tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]]), shape: torch.Size([4, 1])\n",
      "Tensor method unsqueeze at dim 0: tensor([[1, 2, 3, 4]]), shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 1D tensor\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(f\"Original tensor: {x}, shape: {x.shape}\")\n",
    "\n",
    "# Unsqueeze at dimension 0 (adds a new dimension at the beginning)\n",
    "y = torch.unsqueeze(x, 0)\n",
    "print(f\"Unsqueeze at dim 0: {y}, shape: {y.shape}\")\n",
    "\n",
    "# Unsqueeze at dimension 1 (adds a new dimension at the end)\n",
    "z = torch.unsqueeze(x, 1)\n",
    "print(f\"Unsqueeze at dim 1: {z}, shape: {z.shape}\")\n",
    "\n",
    "# You can also use the tensor method\n",
    "a = x.unsqueeze(0)\n",
    "print(f\"Tensor method unsqueeze at dim 0: {a}, shape: {a.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13828eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting tensor x: tensor([[[0.7720, 0.2243]],\n",
      "\n",
      "        [[0.4063, 0.4389]],\n",
      "\n",
      "        [[0.7209, 0.5196]],\n",
      "\n",
      "        [[0.7424, 0.5547]],\n",
      "\n",
      "        [[0.5085, 0.5871]],\n",
      "\n",
      "        [[0.3506, 0.4246]],\n",
      "\n",
      "        [[0.5308, 0.0913]],\n",
      "\n",
      "        [[0.2680, 0.5506]],\n",
      "\n",
      "        [[0.7791, 0.5077]],\n",
      "\n",
      "        [[0.8387, 0.6937]],\n",
      "\n",
      "        [[0.3943, 0.1614]],\n",
      "\n",
      "        [[0.7700, 0.1808]],\n",
      "\n",
      "        [[0.5518, 0.5606]],\n",
      "\n",
      "        [[0.3751, 0.0958]],\n",
      "\n",
      "        [[0.5575, 0.3723]],\n",
      "\n",
      "        [[0.6385, 0.7656]],\n",
      "\n",
      "        [[0.6309, 0.3882]],\n",
      "\n",
      "        [[0.7215, 0.3302]],\n",
      "\n",
      "        [[0.3591, 0.5637]],\n",
      "\n",
      "        [[0.1300, 0.6671]],\n",
      "\n",
      "        [[0.5923, 0.1602]],\n",
      "\n",
      "        [[0.3800, 0.4719]],\n",
      "\n",
      "        [[0.5959, 0.3156]],\n",
      "\n",
      "        [[0.1903, 0.6827]],\n",
      "\n",
      "        [[0.5536, 0.0871]],\n",
      "\n",
      "        [[0.7906, 0.8919]],\n",
      "\n",
      "        [[0.4273, 0.6411]],\n",
      "\n",
      "        [[0.6926, 0.2921]],\n",
      "\n",
      "        [[0.3526, 0.5982]],\n",
      "\n",
      "        [[0.4976, 0.6215]],\n",
      "\n",
      "        [[0.6257, 0.6877]],\n",
      "\n",
      "        [[0.7448, 0.5250]],\n",
      "\n",
      "        [[0.7688, 0.6636]],\n",
      "\n",
      "        [[0.5189, 0.3470]],\n",
      "\n",
      "        [[0.3704, 0.2172]],\n",
      "\n",
      "        [[0.3511, 0.4330]],\n",
      "\n",
      "        [[0.1603, 0.1355]],\n",
      "\n",
      "        [[0.6464, 0.1570]],\n",
      "\n",
      "        [[0.1467, 0.6987]],\n",
      "\n",
      "        [[0.6642, 0.4715]],\n",
      "\n",
      "        [[0.7231, 0.8138]],\n",
      "\n",
      "        [[0.4245, 0.4756]],\n",
      "\n",
      "        [[0.4560, 0.3181]],\n",
      "\n",
      "        [[0.3200, 0.5355]],\n",
      "\n",
      "        [[0.2303, 0.3949]],\n",
      "\n",
      "        [[0.0623, 0.2139]],\n",
      "\n",
      "        [[0.1815, 0.3890]],\n",
      "\n",
      "        [[0.5295, 0.8873]],\n",
      "\n",
      "        [[0.1697, 0.4816]],\n",
      "\n",
      "        [[0.4072, 0.4463]],\n",
      "\n",
      "        [[0.0858, 0.4875]],\n",
      "\n",
      "        [[0.7056, 0.4403]],\n",
      "\n",
      "        [[0.6922, 0.6756]],\n",
      "\n",
      "        [[0.1696, 0.3896]],\n",
      "\n",
      "        [[0.3552, 0.2769]],\n",
      "\n",
      "        [[0.7778, 0.9574]],\n",
      "\n",
      "        [[0.6569, 0.5848]],\n",
      "\n",
      "        [[0.6938, 0.3640]],\n",
      "\n",
      "        [[0.6799, 0.6765]],\n",
      "\n",
      "        [[0.6509, 0.1995]],\n",
      "\n",
      "        [[0.3394, 0.7782]],\n",
      "\n",
      "        [[0.3712, 0.8069]],\n",
      "\n",
      "        [[0.5389, 0.0563]],\n",
      "\n",
      "        [[0.5966, 0.5418]],\n",
      "\n",
      "        [[0.8509, 0.4111]],\n",
      "\n",
      "        [[0.2085, 0.7405]],\n",
      "\n",
      "        [[0.2233, 0.4111]],\n",
      "\n",
      "        [[0.3354, 0.5291]],\n",
      "\n",
      "        [[0.6117, 0.8509]],\n",
      "\n",
      "        [[0.4387, 0.2786]],\n",
      "\n",
      "        [[0.6550, 0.3484]],\n",
      "\n",
      "        [[0.2537, 0.2483]],\n",
      "\n",
      "        [[0.6459, 0.2313]],\n",
      "\n",
      "        [[0.6083, 0.4606]],\n",
      "\n",
      "        [[0.7044, 0.6960]],\n",
      "\n",
      "        [[0.4846, 0.4277]],\n",
      "\n",
      "        [[0.7737, 0.7809]],\n",
      "\n",
      "        [[0.6158, 0.6396]],\n",
      "\n",
      "        [[0.6756, 0.6946]],\n",
      "\n",
      "        [[0.8178, 0.0990]],\n",
      "\n",
      "        [[0.7018, 0.6792]],\n",
      "\n",
      "        [[0.4946, 0.7250]],\n",
      "\n",
      "        [[0.4806, 0.2857]],\n",
      "\n",
      "        [[0.6720, 0.3768]],\n",
      "\n",
      "        [[0.3402, 0.6133]],\n",
      "\n",
      "        [[0.4438, 0.7697]],\n",
      "\n",
      "        [[0.6458, 0.6128]],\n",
      "\n",
      "        [[0.6876, 0.4199]],\n",
      "\n",
      "        [[0.1820, 0.4040]],\n",
      "\n",
      "        [[0.9257, 0.5879]],\n",
      "\n",
      "        [[0.5855, 0.6447]],\n",
      "\n",
      "        [[0.2383, 0.7697]],\n",
      "\n",
      "        [[0.2448, 0.6981]],\n",
      "\n",
      "        [[0.1497, 0.0712]],\n",
      "\n",
      "        [[0.6743, 0.1925]],\n",
      "\n",
      "        [[0.4604, 0.5885]],\n",
      "\n",
      "        [[0.5572, 0.5320]],\n",
      "\n",
      "        [[0.6743, 0.5402]],\n",
      "\n",
      "        [[0.6752, 0.5723]],\n",
      "\n",
      "        [[0.5001, 0.7522]],\n",
      "\n",
      "        [[0.2783, 0.2363]],\n",
      "\n",
      "        [[0.5381, 0.3329]],\n",
      "\n",
      "        [[0.7339, 0.3966]],\n",
      "\n",
      "        [[0.4618, 0.3699]],\n",
      "\n",
      "        [[0.7584, 0.7947]],\n",
      "\n",
      "        [[0.3885, 0.3824]],\n",
      "\n",
      "        [[0.3851, 0.1069]],\n",
      "\n",
      "        [[0.5312, 0.2849]],\n",
      "\n",
      "        [[0.5615, 0.4907]],\n",
      "\n",
      "        [[0.4661, 0.5591]],\n",
      "\n",
      "        [[0.5214, 0.4014]],\n",
      "\n",
      "        [[0.2590, 0.1874]],\n",
      "\n",
      "        [[0.3943, 0.5102]],\n",
      "\n",
      "        [[0.3736, 0.3020]],\n",
      "\n",
      "        [[0.3348, 0.6234]],\n",
      "\n",
      "        [[0.6496, 0.6692]],\n",
      "\n",
      "        [[0.3345, 0.4312]],\n",
      "\n",
      "        [[0.5990, 0.2652]],\n",
      "\n",
      "        [[0.2589, 0.5814]],\n",
      "\n",
      "        [[0.4758, 0.4652]],\n",
      "\n",
      "        [[0.8731, 0.7533]],\n",
      "\n",
      "        [[0.6002, 0.2630]],\n",
      "\n",
      "        [[0.4542, 0.7409]],\n",
      "\n",
      "        [[0.2720, 0.5063]],\n",
      "\n",
      "        [[0.5869, 0.7074]],\n",
      "\n",
      "        [[0.3032, 0.6152]],\n",
      "\n",
      "        [[0.6054, 0.1577]],\n",
      "\n",
      "        [[0.3785, 0.3080]]]), shape: torch.Size([128, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(128, 2)\n",
    "\n",
    "sig_a = torch.sigmoid(a)   \n",
    "# print(f\"Sigmoid of a: {sig_a}, shape: {sig_a.shape}\")\n",
    "\n",
    "m = sig_a.unsqueeze(2)\n",
    "x = sig_a.unsqueeze(1)\n",
    "# print(f\"Resulting tensor m: {m}, shape: {m.shape}\") # [128, 2, 1] * \n",
    "print(f\"Resulting tensor x: {x}, shape: {x.shape}\") # [128, 1, 2] * "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energymodels (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
